<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="When Models Meet Data, Jay&#39;s Blog">
    <meta name="description" content="When Models Meet DataData, Models, and LearningData as Vectors
We assume that our data can be read by a computer, and re">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>When Models Meet Data | Jay&#39;s Blog</title>
    <link rel="icon" type="image/png" href="/favicon.png">
    


    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/css/matery.css">
<link rel="stylesheet" type="text/css" href="/css/my.css">
<link rel="stylesheet" type="text/css" href="/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/css/post.css">




    



    <script src="/libs/jquery/jquery-3.6.0.min.js"></script>

    <script src="https://sdk.jinrishici.com/v2/browser/jinrishici.js" charset="utf-8"></script>

<meta name="generator" content="Hexo 7.2.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
</head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <span class="logo-span">Jay&#39;s Blog</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/galleries" class="waves-effect waves-light">
      
      <i class="fas fa-image" style="zoom: 0.6;"></i>
      
      <span>相册</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <div class="logo-name">Jay&#39;s Blog</div>
        <div class="logo-desc">
            
            Jay&#39;s Blog
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/galleries" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-image"></i>
			
			相册
		</a>
          
        </li>
        
        
    </ul>
</div>


        </div>

        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/3.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">When Models Meet Data</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/Mathematics/">
                                <span class="chip bg-color">Mathematics</span>
                            </a>
                        
                            <a href="/tags/%E7%AC%94%E8%AE%B0/">
                                <span class="chip bg-color">笔记</span>
                            </a>
                        
                            <a href="/tags/MachineLearing/">
                                <span class="chip bg-color">MachineLearing</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/MachineLearing/" class="post-category">
                                MachineLearing
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2024-08-07
                </div>
                

                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    7.6k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    47 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        
        <!-- 是否加载使用自带的 prismjs. -->
        <link rel="stylesheet" href="/libs/prism/prism.min.css">
        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <h1 id="When-Models-Meet-Data"><a href="#When-Models-Meet-Data" class="headerlink" title="When Models Meet Data"></a>When Models Meet Data</h1><h2 id="Data-Models-and-Learning"><a href="#Data-Models-and-Learning" class="headerlink" title="Data, Models, and Learning"></a>Data, Models, and Learning</h2><h3 id="Data-as-Vectors"><a href="#Data-as-Vectors" class="headerlink" title="Data as Vectors"></a>Data as Vectors</h3><ul>
<li>We assume that our data can be read by a computer, and represented adequately in a numerical format. Data is assumed to be tabular, where we think of each row of the table as representing a particular instance or example, and each column to be a particular feature.<br><img src="https://cdn.jsdelivr.net/gh/Eliauk-L/blog-img@img/img/202408072212449.png" alt="Example data from a fictitious human resource database that is not in a numerical format"></li>
<li>Even when we have data in tabular format, there are still choices to be made to obtain a numerical representation. For example, in table, the gender column (a categorical variable) may be converted into numbers $0$ representing “Male” and $1$ representing “Female”. Alternatively, the gender could be represented by numbers −1, +1, respectively. Furthermore, it is often important to use domain knowledge when constructing the representation, such as knowing that university degrees progress from bachelor’s to master’s to PhD or realizing that the postcode provided is not just a string of characters but actually encodes an area in London.</li>
<li>In following table, we converted the data from previous table to a numerical format, and each postcode is represented as two numbers, a latitude and longitude.<br><img src="https://cdn.jsdelivr.net/gh/Eliauk-L/blog-img@img/img/202408072212968.png" alt="A numerical format"></li>
<li>Even numerical data that could potentially be directly read into a machine learning algorithm should be carefully considered for units, scaling, and constraints. Without additional information, one should shift and scale all columns of the dataset such that they have an empirical mean of 0 and an empirical variance of 1.</li>
<li>We assume that a domain expert already converted data appropriately, i.e., each input $x_n $is a $D$-dimensional vector of real numbers, which are called <strong><em>features, attributes, or covariates</em></strong>. And we will use $N$ to denote the number of examples in a dataset and index the examples with lowercase $n = 1, . . . ,N$.</li>
<li>We assume that we are given a set of numerical data, represented as <strong>an array of vectors</strong> . Each row is a particular individual $x_n$, often referred to as an <em>example or data point</em> in machine learning. The subscript $n$ refers to the fact that this is the $n$th example out of a total of $N$ examples in the dataset. Each column represents a particular feature of interest<br>about the example, and we index the features as $d = 1, . . . ,D$. Recall that data is represented as vectors, which means that each example (each data point) is a $D$-dimensional vector.</li>
<li>Let us consider the problem of predicting annual salary from age, based on the data in table. This is called a <em>supervised learning problem</em> where we have a <em>label</em> $y_n$ (the salary) associated with each example $x_n$ (the age). The label $y_n$ has various other names, including <em>target, response variable, and annotation</em>. A dataset is written as a set of example-label pairs $\{(x_1, y_1), . . . , (x_n, y_n), . . . , (x_N, y_N)\}$. The table of examples<br>$\{x_1, . . . , x_N\}$ is often concatenated, and written as $X ∈\mathbb R^{N×D}$. </li>
<li>Since we have vector representations of data, we can manipulate data to find potentially better representations of it. We will discuss finding good representations in two ways: finding <em>lower-dimensional</em> approximations of the original feature vector,like principal component, and using nonlinear <em>higher-dimensional</em> combinations of the original feature vector. </li>
<li>For the high-dimensional representation, we will see an explicit <strong><em>feature map</em></strong> $ϕ(·)$ that allows us to represent inputs $x_n$ using a higher-dimensional representation $ϕ(x_n)$. The main motivation for higher-dimensional representations is that we can construct new features as non-linear combinations of the original features, which in turn may make the learning problem easier.</li>
</ul>
<h3 id="Models-as-Functions"><a href="#Models-as-Functions" class="headerlink" title="Models as Functions"></a>Models as Functions</h3><ul>
<li><p>Once we have data in an appropriate vector representation, we can get to the business of constructing a predictive function (known as a <em>predictor</em>).</p>
</li>
<li><p>A <strong><em>predictor</em></strong> is a <strong><em>function</em></strong> that, when given a particular input example (in our case, a vector of features), produces an output. For now, consider the output to be a single number, i.e., a real-valued scalar output. This can be written as</p>
<script type="math/tex; mode=display">
f:\mathbb R^D\rightarrow \mathbb R</script><p>where the input vector $x$ is $D$-dimensional (has $D$ features), and the function $f$ then applied to it (written as $f(x)$​) returns a real number.We consider the special case of linear functions</p>
<script type="math/tex; mode=display">
f(x)=\theta^Tx+\theta_0</script><p>for unknown $θ$ and $θ_0$.</p>
</li>
</ul>
<h3 id="Models-as-Probability-Distributions"><a href="#Models-as-Probability-Distributions" class="headerlink" title="Models as Probability Distributions"></a>Models as Probability Distributions</h3><ul>
<li>We often consider data to be noisy observations of some true underlying effect, and hope that by applying machine learning we can identify the signal from the noise. Probability theory provides a language for quantifying uncertainty.</li>
<li>Instead of considering a predictor as a single function, we could consider predictors to be <strong><em>probabilistic models</em></strong>, i.e., models describing the distribution of possible functions.</li>
</ul>
<h3 id="Learning-is-Finding-Parameters"><a href="#Learning-is-Finding-Parameters" class="headerlink" title="Learning is Finding Parameters"></a>Learning is Finding Parameters</h3><ul>
<li>The goal of learning is to <em>find a model and its corresponding parameters such that the resulting predictor will perform well on unseen data</em>.</li>
<li>There are conceptually three distinct algorithmic phases when discussing machine learning algorithms:<ol>
<li>Prediction or inference</li>
<li>Training or parameter estimation</li>
<li>Hyperparameter tuning or model selection</li>
</ol>
</li>
<li>The prediction phase is when we use a trained predictor on previously unseen test data. In other words, <em>the parameters and model choice is already fixed and the predictor is applied to new vectors representing new input data points</em>. When we have a probabilistic model the prediction phase is called inference.</li>
<li>The training or parameter estimation phase is when we adjust our predictive model based on training data. We would like to find good predictors given training data, and there are two main strategies for doing so: <em>finding the best predictor based on some measure of quality (sometimes called finding a point estimate), or using Bayesian inference</em>. Finding a point estimate can be applied to both types of predictors, but Bayesian inference requires probabilistic models.</li>
<li>For the non-probabilistic model, we follow the principle of <em>empirical risk minimization.</em> Empirical risk minimization directly provides an optimization problem for finding good parameters. With a statistical model, the principle of maximum likelihood is used to find a good set of parameters.</li>
<li>We simulate the behavior of our predictor on future unseen data using <em>cross-validation</em>. To achieve the goal of performing well on unseen data, we will need to balance between fitting well on training data and finding “simple” explanations of the phenomenon. This trade-off is achieved using <em>regularization</em> (Section 8.2.3) or by adding a <em>prior</em>.</li>
<li>We often need to make high-level modeling decisions about the structure of the predictor, such as the number of components to use or the class of probability distributions to consider. The choice of the number of components is an example of a <strong><em>hyperparameter</em></strong>, and this choice can affect the performance of the model significantly. The problem of choosing among different models is called model selection. For non-probabilistic models, model selection is often done using nested cross-validation.</li>
</ul>
<h2 id="Empirical-Risk-Minimization"><a href="#Empirical-Risk-Minimization" class="headerlink" title="Empirical Risk Minimization"></a>Empirical Risk Minimization</h2><ul>
<li>The general principles of empirical risk minimization are widely applicable and allow us to ask the question of what is learning without explicitly constructing probabilistic models. There are four main design choices:<ul>
<li><em>What is the set of functions we allow the predictor to take?</em></li>
<li><em>How do we measure how well the predictor performs on the training data?</em></li>
<li><em>How do we construct predictors from only training data that performs well on unseen test data?</em></li>
<li><em>What is the procedure for searching over the space of models?</em></li>
</ul>
</li>
</ul>
<h3 id="Hypothesis-Class-of-Functions"><a href="#Hypothesis-Class-of-Functions" class="headerlink" title="Hypothesis Class of Functions"></a>Hypothesis Class of Functions</h3><ul>
<li><p>Assume we are given $N$ examples $x_n ∈\mathbb R^D$ and corresponding scalar labels $y_n ∈\mathbb R$. We consider the supervised learning setting, where we obtain pairs $(x_1, y_1), . . . , (x_N, y_N)$. Given this data, we would like to estimate a predictor $f(·, θ) :\mathbb R^D →\mathbb R$, parametrized by $θ$. We hope to be able to find a good parameter $θ^∗$ such that we fit the data well, that is,</p>
<script type="math/tex; mode=display">
f(x_n,\theta^*)\approx y_n\quad\text{for all}\quad n=1,...,N</script><p>we use the notation $\hat y_n = f(x_n, θ^∗)$ to represent the output of the predictor.</p>
<p>We will describe empirical risk minimization in terms of supervised learning (where we have labels). This simplifies the definition of <em>the hypothesis class and the loss function</em>. It<br>is also common in machine learning to choose a parametrized class of functions, for example <em>affine functions</em>.</p>
<blockquote>
<p>e.g. We introduce the problem of ordinary <em>least-squares regression</em> to illustrate empirical risk minimization. When the label $y_n$ is real-valued, a popular choice<br>of function class for predictors is the set of affine functions. We choose a more compact notation for an affine function by concatenating an additional unit feature $x(0) = 1$ to $x_n$, i.e., $x_n = [1, x^{(1)}_n , x^{(2)}_n , . . . , x^{(D)}_n ]^⊤$. The parameter vector is correspondingly $θ = [θ_0, θ_1, θ_2, . . . , θ_D]^⊤$, allowing us to write the predictor as a linear function</p>
<script type="math/tex; mode=display">
f(x_n,\theta)=\theta^Tx_n</script><p>This linear predictor is equivalent to the affine model</p>
<script type="math/tex; mode=display">
f(x_n,\theta)=\theta_0+\sum_{d=1}^D{\theta_dx_n^{(d)}}</script><p>The predictor takes the vector of features representing a single example $x_n$ as input and produces a real-valued output, i.e., $f :\mathbb R^{D+1} →\mathbb R$. </p>
</blockquote>
</li>
</ul>
<h3 id="Loss-Function-for-Training"><a href="#Loss-Function-for-Training" class="headerlink" title="Loss Function for Training"></a>Loss Function for Training</h3><ul>
<li><p>Consider the label $y_n$ for a particular example; and the corresponding prediction $\hat y_n$ that we make based on $x_n$. To define what it means to fit the data well, we need to specify a loss function $ℓ(y_n, \hat y_n)$ that takes the ground truth label and the prediction as input and produces a non-negative number (referred to as the loss) representing how much error we have made on this particular prediction. Our goal for finding a good parameter vector $θ^∗$ is to minimize the average loss on the set of $N$ training examples.</p>
</li>
<li><p>One assumption that is commonly made in machine learning is that the set of examples $(x_1, y_1), . . . , (x_N, y_N)$ is <strong><em>independent and identically distributed.</em></strong> The word independent means that two data points $(x_i, y_i)$ and $(x_j, y_j)$ do not statistically depend on each other, meaning that the empirical mean is a good estimate of the population mean. This implies that we can use <em>the empirical mean of the loss on the training data</em>.</p>
</li>
<li><p>For a given <em>training set</em> $\{(x_1, y_1), . . . , (x_N, y_N)\}$, we introduce the notation of an example matrix $X := [x_1, . . . , x_N]^⊤ ∈\mathbb R^{N×D}$ and a label vector $y := [y_1, . . . , y_N]^⊤ ∈\mathbb R^N$. Using this matrix notation the average loss is given by</p>
<script type="math/tex; mode=display">
R_{emp}(f,X,y)=\frac{1}{N}\sum_{n=1}^N\ell(y_n,\hat y_n)</script><p>where $\hat y_n = f(x_n, θ)$.Equation is called the <strong><em>empirical risk</em></strong> and depends on three arguments, the predictor $f$ and the data $X, y$. This general strategy for learning is called <strong><em>empirical risk minimization</em></strong>.</p>
<blockquote>
<p>e.g.  Continuing the example of least-squares regression, we specify that we measure the cost of making an error during training using the squared loss $ℓ(y_n,\hat y_n) = (y_n −\hat y_n)^2$. We wish to minimize the empirical risk, which is the average of the losses over the data</p>
<script type="math/tex; mode=display">
\underset{\theta\in\mathbb R^D}{\min}\frac{1}{N}\sum_{n=1}^N(y_n-f(x_n,\theta))^2</script><p>where we substituted the predictor $\hat y_n = f(x_n, θ)$. By using our choice of a linear predictor $f(x_n, θ) = θ^⊤x_n$, we obtain the optimization problem</p>
<script type="math/tex; mode=display">
\underset{\theta\in\mathbb R^D}{\min}\frac{1}{N}\sum_{n=1}^N(y_n-\theta^Tx_n)^2</script><p>This equation can be equivalently expressed in matrix form</p>
<script type="math/tex; mode=display">
\underset{\theta\in\mathbb R^D}{\min}\frac{1}{N}\left\|y-X\theta\right\|^2</script><p>This is known as the <em>least-squares problem.</em> There exists a closed-form analytic solution for this by solving the normal equations.</p>
</blockquote>
</li>
<li><p>We are interested in finding a predictor $f$ (with parameters fixed) that minimizes the <em>expected risk</em></p>
<script type="math/tex; mode=display">
R_{true}(f)=\mathbb E_{x,y}[\ell(y,f(x))]</script><p>where $y$ is the label and $f(x)$ is the prediction based on the example $x$. The notation $R_{true}(f)$ indicates that this is the true risk if we had access to an infinite amount of data. The expectation is over the (infinite) set of all possible data and labels.</p>
</li>
</ul>
<h3 id="Regularization-to-Reduce-Overfitting"><a href="#Regularization-to-Reduce-Overfitting" class="headerlink" title="Regularization to Reduce Overfitting"></a>Regularization to Reduce Overfitting</h3><ul>
<li><p>We simulate this unseen data by holding out <em>a proportion of the whole dataset</em>. This hold out set is referred to as the <strong><em>test set</em></strong>.</p>
</li>
<li><p>In practice, we have only a finite set of data, and hence we split our data into a training and a test set. The training set is used to fit the model, and the test set (not seen by the machine learning algorithm during training) is used to evaluate generalization performance. It is important for the user to not cycle back to a new round of training after having observed the test set.</p>
</li>
<li><p>It turns out that empirical risk minimization can lead to <strong><em>overfitting</em></strong>, i.e., <em>the predictor fits too closely to the training data and does not generalize well to new data</em>. This general phenomenon of having very small average loss on the training set but large average loss on<br>the test set tends to occur when we have little data and a complex hypothesis class.</p>
</li>
<li><p>For a particular predictor $f$ (with parameters fixed), the phenomenon of overfitting occurs when the risk estimate from the training data $R_{emp}(f,X_{train}, y_{train})$ underestimates the expected risk $R_{true}(f)$. Since we estimate the expected risk $R_{true}(f)$ by using the empirical risk on the test set $R_{emp}(f,X_{test}, y_{test})$ if the test risk is much larger than the training risk, this is an indication of overfitting.</p>
</li>
<li><p>Therefore, we need to somehow bias the search for the minimizer of empirical risk by introducing a penalty term, which makes it harder for the optimizer to return an overly flexible predictor. In machine learning, the penalty term is referred to as <strong><em>regularization</em></strong>. <em>Regularization is a way to compromise between accurate solution of empirical risk minimization and the size or complexity of the solution.</em></p>
<blockquote>
<p>e.g. <strong>Regularized Least Squares</strong></p>
<p>Regularization is an approach that discourages complex or extreme solutions to an optimization problem. The simplest regularization strategy is to replace the least-squares problem</p>
<script type="math/tex; mode=display">
\underset{\theta}{\min}{\frac{1}{N}\left\|y-X\theta\right\|^2}</script><p>in the previous example with the “regularized” problem by adding a penalty term involving only $θ$:</p>
<script type="math/tex; mode=display">
\underset{\theta}{\min}{\frac{1}{N}\left\|y-X\theta\right\|^2}+\lambda\left\|\theta\right\|^2</script><p>The additional term $∥θ∥^2$ is called the <strong><em>regularizer</em></strong>, and the parameter $λ$ is the <strong><em>regularization parameter.</em></strong> The regularization parameter trades off minimizing the loss on the training set and the magnitude of the parameters $θ$. It often happens that the magnitude of the parameter values becomes relatively large if we run into overfitting</p>
</blockquote>
</li>
<li><p>The regularization term is sometimes called the <strong><em>penalty term</em></strong>, which biases the vector $θ$ to be closer to the origin. The idea of regularization also appears in probabilistic models as the prior probability of the parameters.</p>
</li>
</ul>
<h3 id="Cross-Validation-to-Assess-the-Generalization-Performance"><a href="#Cross-Validation-to-Assess-the-Generalization-Performance" class="headerlink" title="Cross-Validation to Assess the Generalization Performance"></a>Cross-Validation to Assess the Generalization Performance</h3><ul>
<li><p>We measure the generalization error by estimating it by applying the predictor on test data. This data is also sometimes referred to as the <strong><em>validation set</em></strong>. The validation set is a subset of the available training data that we keep aside. </p>
</li>
<li><p>A practical issue with this approach is that the amount of data is limited, and ideally we would use as much of the data available to train the model. This would require us to keep our validation set $\mathcal V$ small, which then would lead to a noisy estimate (with high variance) of the predictive performance. One solution to these contradictory objectives (large training set, large validation set) is to use <strong><em>cross-validation</em></strong>. $K$-fold cross-validation effectively partitions the data into $K$ chunks, $K − 1$ of which form the training set $\mathcal R$, and<br>the last chunk serves as the validation set $\mathcal V$. Cross-validation iterates through (ideally) all combinations of assignments of chunks to R and V. This procedure is repeated for all $K$ choices for the validation set, and the performance of the model from the $K$ runs is averaged.</p>
</li>
<li><p>We partition our dataset into two sets $\mathcal D =\mathcal R∪\mathcal V$, such that they do not overlap $(\mathcal R ∩\mathcal V = ∅)$, where $\mathcal V$ is the validation set, and train our model on $\mathcal R$. After training, we assess the performance of the predictor $f$ on the validation set $\mathcal V$ (e.g., by computing root mean square error (RMSE) of the trained model on the validation set). More precisely, for each partition $k$ the training data $\mathcal R(k)$ produces a predictor $f(k)$, which is then applied<br>to validation set $\mathcal V(k)$ to compute the empirical risk $R(f^{(k)},\mathcal V^{(k)})$. We cyclet hrough all possible partitionings of validation and training sets and compute the average generalization error of the predictor. Cross-validation approximates the expected generalization error</p>
<script type="math/tex; mode=display">
\mathbb E_v[R(f,\mathcal V)]\approx \frac{1}{K}\sum_{k=1}^KR(f^{(k)},\mathcal V^{(k)})</script><p>where $R(f^{(k)},\mathcal V^{(k)})$ is the risk (e.g., RMSE) on the validation set $\mathcal V(k)$ for predictor $f(k)$.</p>
<p>The approximation has two sources: first, due to the finite training set, which results in not the best possible $f(k)$; and second, due to the finite validation set, which results in an inaccurate estimation of the risk $R(f^{(k)},\mathcal V^{(k)})$.</p>
</li>
<li><p>A potential disadvantage of $K$-fold cross-validation is the computational cost of training the model $K$ times, which can be burdensome if the training cost is computationally expensive.</p>
</li>
<li><p>However, cross-validation is an <em>embarrassingly parallel</em> problem, i.e., little effort is needed to separate the problem into a number of parallel tasks. Given sufficient computing resources (e.g., cloud computing, server farms), cross-validation does not require longer than a single performance assessment.</p>
</li>
</ul>
<h2 id="Parameter-Estimation"><a href="#Parameter-Estimation" class="headerlink" title="Parameter Estimation"></a>Parameter Estimation</h2><h3 id="Maximum-Likelihood-Estimation"><a href="#Maximum-Likelihood-Estimation" class="headerlink" title="Maximum Likelihood Estimation"></a>Maximum Likelihood Estimation</h3><ul>
<li><p>The idea behind <strong><em>maximum likelihood estimation</em></strong> <strong>(MLE)</strong> is to define a function of the parameters that enables us to find a model that fits the data well. </p>
</li>
<li><p>The estimation problem is focused on the likelihood function, or more precisely its negative logarithm. For data represented by a random variable $x$ and for a family of probability densities $p(x | θ)$ parametrized by $θ$, the <em>negative log-likelihood</em> is given by</p>
<script type="math/tex; mode=display">
\mathcal L_x(\theta)=-\log p(x|\theta)</script><p>The notation $\mathcal L_x(θ)$ emphasizes the fact that the parameter $θ$ is varying and the data $x$ is fixed.</p>
</li>
<li><p>For a given dataset $x$, the likelihood allows us to express preferences about different settings of the parameters $θ$, and we can choose the setting that more “likely” has generated the data. We consider the supervised learning setting, where we obtain pairs<br>$(x_1, y_1), . . . , (x_N, y_N)$ with $x_n ∈\mathbb R^D$ and labels $y_n ∈\mathbb R$. We are interested in constructing a predictor that takes a feature vector xn as input and produces a prediction $y_n$ (or something close to it), i.e., given a vector $x_n$ we want the probability distribution of the label $y_n$. In other words, we specify the conditional probability distribution of the labels given the examples for the particular parameter setting $θ$.</p>
<blockquote>
<p>e.g The first example that is often used is to specify that the conditional probability of the labels given the examples is a <em>Gaussian distribution</em>. In other words, we assume that we can explain our observation uncertainty by independent Gaussian noise with zero mean,$\varepsilon_n\sim\mathcal N(0,\sigma^2)$. We further assume that the linear model $x^⊤_n θ$ is used for<br>prediction. This means we specify a Gaussian likelihood for each example label pair $(x_n, y_n)$,</p>
<script type="math/tex; mode=display">
p(y_n|x_n,\theta)=\mathcal N(y_n|x_n^T\theta,\sigma^2)</script></blockquote>
</li>
<li><p>We assume that the set of examples $(x_1, y_1), . . . , (x_N, y_N)$ are <strong><em>independent and identically distributed</em></strong> (i.i.d.). The word “independent”  implies that the likelihood involving the whole dataset $(\mathcal Y = \{y_1, . . . , y_N\}$ and $\mathcal X = \{x_1, . . . , x_N\})$ factorizes into a product of the likelihoods of each individual example</p>
<script type="math/tex; mode=display">
p(\mathcal Y|\mathcal X,\theta)=\prod_{n=1}^N{p(y_n|x_n,\theta)}</script><p>where $p(y_n|x_n,θ)$ is a particular distribution. The expression “identically distributed” means that each term in the product is of the same distribution, and all of them share the same parameters.</p>
</li>
<li><p>Hence, in machine learning we often consider the negative log-likelihood</p>
<script type="math/tex; mode=display">
\mathcal L(\theta)=-\log{p(\mathcal Y|\mathcal X,\theta)}=-\sum_{n=1}^N\log p(y_n|x_n,\theta)</script><p>To find a good parameter vector $θ$ that explains the data $(x_1, y_1), . . . , (x_N, y_N)$ well, minimize the negative log-likelihood $L(θ)$ with respect to $θ$.</p>
<blockquote>
<p>e.g. Continuing on our example of Gaussian likelihoods, the negative log-likelihood can be rewritten as</p>
<script type="math/tex; mode=display">
\begin{split}
\mathcal L(\theta)&=-\sum_{n=1}^N\log p(y_n|x_n,\theta)=-\sum_{n=1}^N\log \mathcal N(y_n|x^T_n\theta,\sigma^2)\\
&=-\sum_{n=1}^N\log{\frac{1}{\sqrt{2\pi\sigma^2}}\exp\left(-\frac{(y_n-x^T_n\theta)^2}{2\sigma^2}\right)}\\
&=-\sum_{n=1}^N\log{\exp\left(-\frac{(y_n-x^T_n\theta)^2}{2\sigma^2}\right)}-\sum_{n=1}^N\log{\frac{1}{\sqrt{2\pi\sigma^2}}}\\
&=\frac{1}{2\sigma^2}\sum_{n=1}^N(y_n-x^T_n\theta)^2-\sum_{n=1}^N\log{\frac{1}{\sqrt{2\pi\sigma^2}}}
\end{split}</script><p>As $σ$ is given, the second term is constant, and minimizing $L(θ)$ corresponds to solving the least-squares problem  expressed in the first term.</p>
</blockquote>
</li>
<li><p>It turns out that for Gaussian likelihoods the resulting optimization problem corresponding to maximum likelihood estimation has a closedform solution. Maximum likelihood estimation may suffer from overfitting , analogous to unregularized empirical risk minimization.</p>
</li>
<li><p>For other likelihood functions, i.e., if we model our noise with non-Gaussian distributions, maximum likelihood estimation may not have a closed-form analytic solution. In this case, we resort to numerical optimization methods.</p>
</li>
</ul>
<h3 id="Maximum-A-Posteriori-Estimation"><a href="#Maximum-A-Posteriori-Estimation" class="headerlink" title="Maximum A Posteriori Estimation"></a>Maximum A Posteriori Estimation</h3><ul>
<li><p>If we have prior knowledge about the distribution of the parameters $θ$, we can multiply an additional term to the likelihood. This additional term is a prior probability distribution on parameters $p(θ)$. For a given prior, after observing some data $x$, how should we update the distribution of $θ$?  Bayes’ theorem,  gives us a principled tool to update our probability distributions of random variables. It allows us to compute a <strong><em>posterior distribution</em></strong>$p(\theta|x)$ (the more specific knowledge) on the parameters $θ$ from general prior statements (prior distribution) $p(θ)$ and the function $p(x | θ)$ that links the parameters θ and the observed data $x$ (called the likelihood):</p>
<script type="math/tex; mode=display">
p(\theta|x)=\frac{p(x|\theta)p(\theta)}{p(x)}</script></li>
<li><p>Recall that we are interested in finding the parameter $θ$ that maximizes the posterior. Since the distribution $p(x)$ does not depend on $θ$, we can ignore the value of the denominator for the optimization and obtain</p>
<script type="math/tex; mode=display">
p(\theta|x)\propto p(x|\theta)p(\theta)</script></li>
<li><p>Instead of estimating the minimum of the negative log-likelihood, we now estimate the minimum of the negative log-posterior, which is referred to as <strong><em>maximum a posteriori estimation (MAP estimation).</em></strong></p>
</li>
<li><p>The maximum likelihood estimate $θ_{ML}$ possesses the following properties:</p>
<ul>
<li>Asymptotic consistency: The MLE converges to the true value in the limit of infinitely many observations, plus a random error that is approximately normal.</li>
<li>The size of the samples necessary to achieve these properties can be quite large.</li>
<li>The error’s variance decays in 1/N, where N is the number of data points.</li>
<li>Especially, in the “small” data regime, maximum likelihood estimation can lead to <em>overfitting</em>.</li>
</ul>
</li>
</ul>
<h3 id="Model-Fitting"><a href="#Model-Fitting" class="headerlink" title="Model Fitting"></a>Model Fitting</h3><ul>
<li><p>When we talk about “fitting”, we typically mean optimizing/learning model parameters so that they minimize some loss function.</p>
</li>
<li><p>The parametrization of the model defines a model class $M_θ$ with which we can operate. For example, in a linear regression setting, we may define the relationship between inputs $x$ and (noise-free) observations $y$ to be $y = ax + b$, where $θ := \{a, b\}$ are the model parameters. In this case, the model parameters $θ$ describe the family of affine functions, i.e., straight lines with slope $a$, which are offset from $0$ by $b$. </p>
</li>
<li><p>Assume the data comes from a model $M^∗$, which is unknown to us. For a given training dataset, we optimize $θ$ so that $M_θ$ is as close as possible to $M^∗$, where the “closeness” is defined by the objective function we optimize (e.g., squared loss on the training data). </p>
</li>
<li><p>Figure illustrates a setting where we have a small model class (indicated by the circle $M^θ$), and the data generation model $M^∗$ lies outside the set of considered models. We begin our parameter search at $M_{θ_0}$ . After the optimization, i.e., when we obtain the best possible parameters $θ^∗$, we distinguish three different cases: (i) overfitting, (ii) underfitting, and (iii) fitting well.<br><img src="https://cdn.jsdelivr.net/gh/Eliauk-L/blog-img@img/img/202408072212012.png" alt="Model fitting"></p>
</li>
<li><p>Roughly speaking, <strong><em>overfitting</em></strong> refers to the situation where the parametrized model class is too rich to model the dataset generated by $M^∗$, i.e., $M_θ$ could model much more complicated datasets. For instance, if the dataset was generated by a linear function, and we define $M_θ$ to be the class of seventh-order polynomials, we could model not only linear functions, but also polynomials of degree two, three, etc. Models that overfit typically have <em>a large number of parameters</em>. An observation we often make is that the overly flexible model class $M_θ$ uses all its modeling power to reduce the training error. <em>If the training data is noisy, it will therefore find some useful signal in the noise itself</em>. This will cause enormous problems when we predict away from the training data.<br><img src="https://cdn.jsdelivr.net/gh/Eliauk-L/blog-img@img/img/202408072212650.png" alt="Fitting of different model classes to a regression dataset."></p>
</li>
<li><p>When we run into <strong><em>underfitting</em></strong>, we encounter the opposite problem where the model class $M_θ$ is not rich enough. For example, if our dataset was generated by a sinusoidal function, but $θ$ only parametrizes straight lines, the best optimization procedure will not get us close to the true model. However, we still optimize the parameters and find the best straight line that models the dataset. Models that underfit typically have <em>few parameters</em>.</p>
</li>
<li><p>The third case is when the parametrized model class is about right. Then, our model fits well, i.e., it neither overfits nor underfits. This means our model class is just rich enough to describe the dataset we are given.</p>
</li>
<li><p>When restricting the predictor to have linear form with an additional nonlinear function $φ$ applied to the output, i.e.,</p>
<script type="math/tex; mode=display">
p(y_n|x_n,\theta)=\varphi(\theta^Tx_n)</script><p>we can consider other models for other prediction tasks, such as binary classification or modeling count data. The class of models, which have linear dependence between parameters and data, and have potentially nonlinear transformation $φ$ (called a <em>link function</em>), is referred to as <strong><em>generalized linear models</em></strong>.</p>
</li>
</ul>
<h2 id="Probabilistic-Modeling-and-Inference"><a href="#Probabilistic-Modeling-and-Inference" class="headerlink" title="Probabilistic Modeling and Inference"></a>Probabilistic Modeling and Inference</h2><h3 id="Probabilistic-Models"><a href="#Probabilistic-Models" class="headerlink" title="Probabilistic Models"></a>Probabilistic Models</h3><ul>
<li>Probabilistic models represent the uncertain aspects of an experiment as probability distributions. In probabilistic modeling, the joint distribution $p(x, θ)$ of the observed<br>variables $x$ and the hidden parameters $θ$ is of central importance: It encapsulates information from the following:<ul>
<li>The prior and the likelihood.</li>
<li>The marginal likelihood $p(x)$, which will play an important role in model selection, can be computed by taking the joint distribution and integrating out the parameters.</li>
<li>The posterior, which can be obtained by dividing the joint by the marginal likelihood.</li>
</ul>
</li>
<li>Only the joint distribution has this property. Therefore, <em>a probabilistic model is specified by the joint distribution of all its random variables.</em></li>
</ul>
<h3 id="Bayesian-Inference"><a href="#Bayesian-Inference" class="headerlink" title="Bayesian Inference"></a>Bayesian Inference</h3><ul>
<li><p>A key task in machine learning is to take a model and the data to uncover the values of the model’s hidden variables $θ$ given the observed variables $x$.</p>
</li>
<li><p>We already discussed two ways for estimating model parameters $θ$ using maximum likelihood or maximum a posteriori estimation. In both cases, we obtain a single-best value for $θ$ so that the key algorithmic problem of parameter estimation is <strong><em>solving an optimization problem</em></strong>. Once these point estimates $θ^∗$ are known, we use them to makep redictions. More specifically, the predictive distribution will be $p(x | θ^∗)$, where we use $θ^∗$ in the likelihood function.</p>
</li>
<li><p>These decision-making systems typically have different objective functions than the likelihood, a squared-error loss or a mis-classification error. Therefore, having the full posterior distribution around can be extremely useful and leads to more robust decisions. <strong><em>Bayesian inference</em></strong> is about finding this posterior distribution.</p>
</li>
<li><p>For a dataset $\mathcal X$, a parameter prior $p(θ)$, and a likelihood function, the posterior</p>
<script type="math/tex; mode=display">
p(\theta|\mathcal X)=\frac{p(\mathcal X|\theta)p(\theta)}{p(\mathcal X)},\quad p(\mathcal X)=\int{p(\mathcal X|\theta)p(\theta)d\theta}</script><p>is obtained by applying Bayes’ theorem. The key idea is to exploit Bayes’ theorem to invert the relationship between the parameters $θ$ and the data $\mathcal X$ (given by the likelihood) to obtain the posterior distribution $p(θ |\mathcal X)$.</p>
</li>
<li><p>The implication of having a posterior distribution on the parameters is that it can be used to propagate uncertainty from the parameters to the data. More specifically, with a distribution $p(θ)$ on the parameters our predictions will be</p>
<script type="math/tex; mode=display">
p(x)=\int p(x|\theta)p(\theta)d\theta=\mathbb E_\theta[p(x|\theta)]</script><p>and they no longer depend on the model parameters $θ$, which have been marginalized<br>/integrated out. Equation reveals that the prediction is an average over all plausible parameter values $θ$, where the plausibility is encapsulated by the parameter distribution $p(θ)$.</p>
</li>
<li><p><strong>parameter estimation vs Bayesian inference</strong></p>
<ul>
<li>Parameter estimation via maximum likelihood or MAP estimation yields a consistent<br>point estimate $θ^∗$ of the parameters, and the key computational problem to be solved is <em>optimization</em>.</li>
<li>Bayesian inference yields a (posterior) distribution, and the key computational problem to be solved is <em>integration</em>.</li>
<li>Predictions with point estimates are straightforward, whereas predictions in the Bayesian framework require solving another integration problem.</li>
<li>Bayesian inference gives us a principled way to incorporate prior knowledge, account for side information, and incorporate structural knowledge, all of which is not easily done in the context of parameter estimation.</li>
</ul>
</li>
</ul>
<h3 id="Latent-Variable-Models"><a href="#Latent-Variable-Models" class="headerlink" title="Latent-Variable Models"></a>Latent-Variable Models</h3><ul>
<li><p>In practice, it is sometimes useful to have additional latent variables $z$ (besides the model parameters $θ$) as part of the model. These latent variables are different from the model parameters $θ$ as they do <em>not parametrize the model explicitly</em>. Latent variables may <em>describe the data-generating process</em>, thereby contributing to the inter- pretability of the model. They also often <em>simplify the structure of the model</em> and allow us to define simpler and richer model structures.</p>
</li>
<li><p>Learning in latent-variable models (at least via maximum likelihood) can be done in a principled way using the <em>expectation maximization</em> (EM) algorithm.</p>
</li>
<li><p>Latent-variable models also allow us to define the process thatgenerates data from parameters. Denoting data by $x$, the model parameters by $θ$ and the latent variables by $z$, we obtain the conditional distribution</p>
<script type="math/tex; mode=display">
p(x|\theta,z)</script><p>that allows us to generate data for any model parameters and latent variables. Given that $z$ are latent variables, we place a prior $p(z)$ on them.</p>
</li>
<li><p>Models with latent variables can be used for parameter learning and inference.  First, we compute the likelihood $p(x | θ)$ of the model, which does not depend on the latent variables. Second, we use this likelihood for parameter estimation or Bayesian inference.</p>
</li>
<li><p>Since the likelihood function $p(x | θ)$ is the predictive distribution of the data given the model parameters, we need to marginalize out the latent variables so that</p>
<script type="math/tex; mode=display">
p(x|\theta)=\int p(x|z,\theta)p(z)dz</script><p>where $p(z)$ is the prior on the latent variables. Note that the likelihood must not depend on the latent variables $z$, but it is only a function of the data x and the model parameters $θ$,i.e. the likelihood is a function of the data and the model parameters, but is independent of the latent variables.</p>
</li>
<li><p>Moreover, with the likelihood Bayesian inference in a latent-variable model works in the usual way: We place a prior $p(θ)$ on the model parameters and use Bayes’ theorem to obtain a posterior distribution</p>
<script type="math/tex; mode=display">
p(\theta|\mathcal X)=\frac{p(\mathcal X|\theta)p(\theta)}{p(\mathcal X)}</script><p>over the model parameters given a dataset $\mathcal X$. The posterior can be used for predictions within a Bayesian inference framework.</p>
</li>
<li><p>One challenge we have in this latent-variable model is that the likelihood $p(\mathcal X | θ)$ requires the marginalization of the latent variables. Except when we choose a conjugate prior $p(z) $for $p(x | z, θ)$, the marginalization is not analytically tractable, and we need to resort to approximations. Similar to the parameter posterior we can compute a posterior on the latent variables according to</p>
<script type="math/tex; mode=display">
p(z|\mathcal X)=\frac{p(\mathcal X|z)p(z)}{p(\mathcal X)},\quad 
p(\mathcal X|z)=\int p(\mathcal X|z,\theta)p(\theta)d\theta</script><p>where $p(z)$ is the prior on the latent variables and $p(X | z)$ requires us to integrate out the model parameters $θ$.</p>
</li>
<li><p>Given the difficulty of solving integrals analytically, it is clear that marginalizing out both the latent variables and the model parameters at the same time is not possible in general. A quantity that is easier to compute is <em>the posterior distribution on the latent variables, but conditioned on the model parameters</em>, i.e.,</p>
<script type="math/tex; mode=display">
p(z|\mathcal X,\theta)=\frac{p(\mathcal X|z,\theta)p(z)}{p(\mathcal X|\theta)}</script><p>where $p(z)$ is the prior on the latent variables and $p(\mathcal X | z, θ)$ is given.</p>
</li>
</ul>
<h2 id="Directed-Graphical-Models"><a href="#Directed-Graphical-Models" class="headerlink" title="Directed Graphical Models"></a>Directed Graphical Models</h2><ul>
<li>We will introduce a graphical language for specifying a probabilistic model, called the <strong><em>directed graphical model</em></strong>. It provides a compact and succinct way to specify probabilistic models, and allows the reader to visually parse dependencies between random variables. <em>Directed graphical models are also known as Bayesian networks.</em></li>
<li>In a graphical model, nodes are random variables. The nodes represent the random variables $a, b, c$. Edges represent probabilistic relations between variables, e.g., conditional probabilities.</li>
<li><em>Not every distribution can be represented in a particular choice of graphical model.</em></li>
<li>Probabilistic graphical models have some convenient properties:<ul>
<li>They are a simple way to visualize the structure of a probabilistic model.</li>
<li>They can be used to design or motivate new kinds of statistical models.</li>
<li>Inspection of the graph alone gives us insight into properties, e.g., conditional independence.</li>
<li>Complex computations for inference and learning in statistical models can be expressed in terms of graphical manipulations.</li>
</ul>
</li>
</ul>
<h3 id="Graph-Semantics"><a href="#Graph-Semantics" class="headerlink" title="Graph Semantics"></a>Graph Semantics</h3><ul>
<li><p>Directed graphical models/Bayesian networks are a method for representing <strong>conditional dependencies in a probabilistic model.</strong> Directed links (arrows) between two nodes (random variables) indicate conditional probabilities. For example, the arrow between a and b in Figure(a) gives the conditional probability $p(b | a)$ of b given $a$.<br><img src="https://cdn.jsdelivr.net/gh/Eliauk-L/blog-img@img/img/202408072212775.png" alt="Examples of directed graphical models"></p>
</li>
<li><p>Directed graphical models can be derived from joint distributions if we know something about their factorization.</p>
<blockquote>
<p>e.g Consider the joint distribution</p>
<script type="math/tex; mode=display">
p(a,b,c)=p(c|a,b)p(b|a)p(a)</script><p>of three random variables $a, b, c$. The factorization of the joint distribution tells us something about the relationship between the random variables:</p>
<ul>
<li>$c$ depends directly on $a$ and $b$.</li>
<li>$b$ depends directly on $a$.</li>
<li>$a$ depends neither on $b$ nor on $c$.</li>
</ul>
<p>For the factorization, we obtain the directed graphical model in Figure(a).</p>
</blockquote>
</li>
<li><p>We can construct the corresponding directed graphical model from a factorized joint distribution as follows:</p>
<ol>
<li>Create a node for all random variables.</li>
<li>For each conditional distribution, we add a directed link (arrow) to the graph from the nodes corresponding to the variables on which the distribution is conditioned.</li>
</ol>
</li>
<li><p>The graph layout depends on the choice of factorization of the joint distribution.</p>
</li>
<li><p>Now, we will describe how to extract the joint distribution of a set of random variables from a given graphical model.</p>
<blockquote>
<p>e.g. Looking at the graphical model in Figure(b), we exploit two properties:</p>
<ul>
<li>The joint distribution $p(x_1, . . . , x_5)$ we seek is the product of a set of conditionals, one for each node in the graph. In this particular example, we will need five conditionals.</li>
<li>Each conditional depends only on the parents of the corresponding node in the graph. For example, $x_4$ will be conditioned on $x_2$.</li>
</ul>
<p>These two properties yield the desired factorization of the joint distribution</p>
<script type="math/tex; mode=display">
p(x_1,x_2,x_3,x_4,x_5)=p(x_1)p(x_5)p(x_2|x_5)p(x_3|x_1,x_2)p(x_4|x_2)</script></blockquote>
</li>
<li><p>In general, the joint distribution $p(x) = p(x_1, . . . , x_K)$ is given as</p>
<script type="math/tex; mode=display">
p(x)=\prod_{k=1}^Kp(x_k|P_{a_k})</script><p>where $P_{ak}$ means “the parent nodes of $x_k$”. Parent nodes of $x_k$ are nodes that have arrows pointing to $x_k$.</p>
</li>
</ul>
<h3 id="Conditional-Independence-and-d-Separation"><a href="#Conditional-Independence-and-d-Separation" class="headerlink" title="Conditional Independence and d-Separation"></a>Conditional Independence and d-Separation</h3><ul>
<li><p>Directed graphical models allow us to find conditional independence relationship properties of the joint distribution only by looking at the graph. A concept called <strong><em>d-separation</em></strong> is key to this.</p>
</li>
<li><p>Consider a general directed graph in which $\mathcal {A, B, C}$ are arbitrary nonintersecting sets of nodes (whose union may be smaller than the complete set of nodes in the graph). We wish to ascertain whether a particular conditional independence statement, “$\mathcal A$ is conditionally independent of $\mathcal B$ given $\mathcal C$”, denoted by <img src="https://cdn.jsdelivr.net/gh/Eliauk-L/blog-img@img/img/202408072212032.png" alt="conditionally independent"> is implied by a given directed acyclic graph. To do so, we consider all possible trails (paths that <em>ignore the direction of the arrows</em>) from <strong>any node in $\mathcal A$ to any nodes in $\mathcal B$.</strong> Any such path is said to be <strong>blocked</strong> if it includes any node such that <strong><em>either</em></strong> of the following are true:</p>
<ul>
<li><strong>The arrows on the path meet either <em>head to tail</em> or <em>tail to tail</em> at the node, and the node is in the set $\mathcal C$.</strong></li>
<li><strong>The arrows meet <em>head to head</em> at the node, and neither the node nor any of its descendants is in the set $\mathcal C$.</strong></li>
</ul>
<p>If all paths are <strong>blocked</strong>, then $\mathcal A$ is said to be <strong><em>d-separated</em></strong> from $B$ by $C$, and the joint distribution over all of the variables in the graph will satisfy <img src="https://cdn.jsdelivr.net/gh/Eliauk-L/blog-img@img/img/202408072212032.png" alt="conditionally independent">)</p>
<blockquote>
<p>e.g Conditional Independence</p>
<p><img src="https://cdn.jsdelivr.net/gh/Eliauk-L/blog-img@img/img/202408072213741.png" alt="D-separation example"></p>
<p>Consider the graphical model in Figure. Visual inspection gives us</p>
<p><img src="https://cdn.jsdelivr.net/gh/Eliauk-L/blog-img@img/img/202408072213379.png" alt="result"></p>
</blockquote>
</li>
<li><p>There are three main types of probabilistic graphical models:</p>
<ul>
<li>Directed graphical models</li>
<li>Undirected graphical models</li>
<li>Factor graphs;</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/Eliauk-L/blog-img@img/img/202408072213623.png" alt="Three types of graphical models"></p>
</li>
</ul>
<h2 id="Model-Selection"><a href="#Model-Selection" class="headerlink" title="Model Selection"></a>Model Selection</h2><h3 id="Nested-Cross-Validation"><a href="#Nested-Cross-Validation" class="headerlink" title="Nested Cross-Validation"></a>Nested Cross-Validation</h3><ul>
<li><p>Recall that cross-validation provides an estimate of the generalization error by repeatedly splitting the dataset into training and validation sets. For each split, we can perform another round of cross-validation. This is sometimes referred to as <strong><em>nested cross-validation</em></strong>.<br><img src="https://cdn.jsdelivr.net/gh/Eliauk-L/blog-img@img/img/202408072213499.png" alt="Nested cross-validation"></p>
</li>
<li><p>The inner level is used to estimate <em>the performance of a particular choice of model</em><br><em>or hyperparameter on a internal validation set</em>. The outer level is used to estimate <em>generalization performance</em> for the best choice of model chosen by the inner loop.</p>
</li>
<li><p>To distinguish the two levels, the set used to estimate the generalization performance is often called the <em>test set</em> and the set used for choosing the best model is called the <em>validation set</em>. </p>
</li>
<li><p>The inner loop estimates the expected value of the generalization error for a given model, by approximating it using the empirical error on the validation set,i.e.,</p>
<script type="math/tex; mode=display">
\mathbb E_{\mathcal V}[R(\mathcal V|M)]\approx \frac{1}{K}\sum_{k=1}^K{R(\mathcal V^{(k)}|M)}</script><p>where $R(\mathcal V |M)$ is the empirical risk (e.g., root mean square error) on the validation set $\mathcal V $for model $M$. We repeat this procedure for all models and choose the model that performs best. </p>
</li>
<li><p>Note that cross-validation not only gives us the expected generalization error, but we can also obtain high-order statistics, e.g., the standard error, an estimate of how uncertain the mean estimate is. Once the model is chosen, we can evaluate the final performance on the test set.</p>
</li>
</ul>
<h3 id="Bayesian-Model-Selection"><a href="#Bayesian-Model-Selection" class="headerlink" title="Bayesian Model Selection"></a>Bayesian Model Selection</h3><ul>
<li><p>We assume that simpler models are less prone to overfitting than complex models, and hence the objective of model selection is to find the simplest model that explains the data reasonably well. This concept is also known as <strong><em>Occam’s razor</em></strong>.</p>
</li>
<li><p>If we treat model selection as a hypothesis testing problem, we are looking for the simplest hypothesis that is consistent with the data.</p>
</li>
<li><p>One may consider placing a prior on models that favors simpler models. However, it is not necessary to do this: An “automatic Occam’s Razor” is quantitatively embodied in the application of Bayesian probability.</p>
</li>
<li><p>Figure gives us the basic intuition why complex and very expressive models may turn out to be a less probable choice for modeling a given dataset $\mathcal D$.<br><img src="https://cdn.jsdelivr.net/gh/Eliauk-L/blog-img@img/img/202408072213068.png" alt="Bayesian inference embodies Occam’s razor"><br>Let us think of the horizontal axis representing the space of all possible datasets $\mathcal D$. If we are interested int he posterior probability $p(M_i |\mathcal D)$ of model $M_i$ given the data $\mathcal D$, we can<br>employ Bayes’ theorem. Assuming a uniform prior $p(M)$ over all models, Bayes’ theorem rewards models in proportion to how much they predicted the data that occurred. This prediction of the data given model $M_i, p(\mathcal D |M_i)$, is called the <strong><em>evidence</em></strong> for $M_i$. A simple model $M_1$ can only predict a small number of datasets, which is shown by $p(\mathcal D|M_1)$; a more powerful model $M_2$ that has, e.g., more free parameters than $M_1$, is able to predict a greater variety of datasets. This means, however, that $M_2$ does not predict the datasets in region $C$ as well as $M_1$. Suppose that equal prior probabilities have been assigned to the two models. Then, if the dataset falls into region $C$, the less powerful model $M_1$ is the more probable model.</p>
</li>
<li><p>Let us consider a finite number of models $M = {M_1, . . . ,M_K}$, where each model $M_k$ possesses parameters $θ_k$. In <em>Bayesian model selection</em>, we place a prior $p(M)$ on the set of models. The corresponding <em>generative process</em> that allows us to generate data from this model is</p>
<script type="math/tex; mode=display">
M_k\sim p(M)\\
\theta_k\sim p(\theta|M_k)\\
\mathcal D\sim p(\mathcal D|\theta_k)</script><p><img src="https://cdn.jsdelivr.net/gh/Eliauk-L/blog-img@img/img/202408072213624.png" alt="Illustration of the hierarchical generative process in Bayesian model selection."></p>
<p>Given a training set $\mathcal D$, we apply Bayes’ theorem and compute the posterior distribution over models as</p>
<script type="math/tex; mode=display">
p(M_k|\mathcal D)\propto p(M_k)p(\mathcal D|M_k)</script><p>Note that this posterior no longer depends on the model parameters $θ_k$ because they have been integrated out in the Bayesian setting since</p>
<script type="math/tex; mode=display">
p(\mathcal D|M_k)=\int p(\mathcal D|\theta_k)p(\theta_k|M_k)d\theta_k</script><p>where $p(θ_k |M_k)$ is the prior distribution of the model parameters $θ_k$ of model $M_k$. This term is referred to as the <em>model evidence</em> or <em>marginal likelihood</em>. From the posterior, we determine the MAP estimate</p>
<script type="math/tex; mode=display">
M^*=\arg\underset{M_k}{\max}{p(M_k|\mathcal D)}</script><p>With a uniform prior $p(M_k) =\frac{1}{K}$ , which gives every model equal (prior) probability, determining the MAP estimate over models amounts to picking the model that maximizes the model evidence.</p>
</li>
<li><p>There are some important differences between a likelihood and a marginal likelihood (evidence): While the likelihood is prone to overfitting, the marginal likelihood is typically not as the model parameters have been marginalized out. Furthermore, the marginal likelihood automatically embodies a trade-off between model complexity and data fit (Occam’s razor).</p>
</li>
</ul>
<h3 id="Bayes-Factors-for-Model-Comparison"><a href="#Bayes-Factors-for-Model-Comparison" class="headerlink" title="Bayes Factors for Model Comparison"></a>Bayes Factors for Model Comparison</h3><ul>
<li><p>Consider the problem of comparing two probabilistic models $M_1,M_2$, given a dataset $\mathcal D$. If we compute the posteriors $p(M_1 |\mathcal D)$ and $p(M_2 |\mathcal D)$, we can compute the ratio of the posteriors</p>
<script type="math/tex; mode=display">
\underset{\text{posterior odds}}{\underbrace{\frac{p(M_1|\mathcal D)}{p(M_2|\mathcal D)}}}
=\frac{\frac{p(\mathcal D|M_1)p(M_1)}{p(\mathcal D)}}{\frac{p(\mathcal D|M_2)p(M_2)}{p(\mathcal D)}}=
\underset{\text{prior odds}}{\underbrace{\frac{p(M_1)}{p(M_2)}}}
\underset{\text{Bayes factor}}{\underbrace{\frac{p(\mathcal D|M_1)}{p(\mathcal D|M_2)}}}</script><p>The ratio of the posteriors is also called the <em>posterior odds</em>. The first fraction on the right-hand side, the <em>prior odds</em>, measures how much our prior (initial) beliefs favor $M_1$ over $M_2$. The ratio of the marginal likelihoods (second fraction on the right-hand-side) is called the <em>Bayes factor</em> and measures how well the data $D$ is predicted by $M_1$ compared to $M_2$.</p>
</li>
<li><p>The Jeffreys-Lindley paradox states that the “Bayes factor always favors the simpler model since the probability of the data under a complex model with a diffuse prior will be very small”. Here, a diffuse prior refers to a prior that does not favor specific models, i.e., many models are a priori plausible under this prior.</p>
</li>
<li><p>If we choose a uniform prior over models, <em>the prior odds term is 1</em>, i.e., the posterior odds is the ratio of the marginal likelihoods (Bayes factor) $\frac{p(\mathcal D|M_1)}{p(\mathcal D|M_2)}$.  <strong>If the Bayes factor is greater than 1, we choose model $M_1$, otherwise model $M_2$.</strong></p>
</li>
<li><p>If we focus on the maximum likelihood estimate, there exist a number of heuristics for model selection that discourage overfitting. They are called <em>information criteria</em>, and we choose the model with the largest value. The <em>Akaike information criterion (AIC)</em></p>
<script type="math/tex; mode=display">
\log p(x|\theta)-M</script><p>corrects for the bias of the maximum likelihood estimator by addition of a penalty term to compensate for the overfitting of more complex models with lots of parameters. Here, <strong>$M$ is the number of model parameters</strong>. The AIC estimates the relative information lost by a given model.</p>
</li>
<li><p>The <em>Bayesian information criterion (BIC)</em></p>
<script type="math/tex; mode=display">
\log p(x)=\log \int    p(x|\theta)p(\theta)d\theta\approx \log p(x|\theta)-\frac{1}{2}M\log N</script><p>can be used for exponential family distributions. Here, $N$ is the number of data points and $M$ is the number of parameters. BIC penalizes modelc omplexity more heavily than AIC.</p>
</li>
</ul>
<blockquote>
<p><strong>Bibliography:</strong></p>
<ol>
<li>Mathematics for Machine Learning_Marc Peter Deisenroth_2020</li>
</ol>
</blockquote>

                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">Jay</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="http://Eliauk-L.github.io/2024/08/07/whenmodelsmeetdata/">http://Eliauk-L.github.io/2024/08/07/whenmodelsmeetdata/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/about" target="_blank">Jay</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/Mathematics/">
                                    <span class="chip bg-color">Mathematics</span>
                                </a>
                            
                                <a href="/tags/%E7%AC%94%E8%AE%B0/">
                                    <span class="chip bg-color">笔记</span>
                                </a>
                            
                                <a href="/tags/MachineLearing/">
                                    <span class="chip bg-color">MachineLearing</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="qq, qzone, wechat, weibo, douban" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/2024/08/08/jenkins-springboot-gitee-zi-dong-hua-bu-shu/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/2.jpg" class="responsive-img" alt="Jenkins+SpringBoot+Gitee自动化部署">
                        
                        <span class="card-title">Jenkins+SpringBoot+Gitee自动化部署</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2024-08-08
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/SpringBoot/" class="post-category">
                                    SpringBoot
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/%E7%AC%94%E8%AE%B0/">
                        <span class="chip bg-color">笔记</span>
                    </a>
                    
                    <a href="/tags/SpringBoot/">
                        <span class="chip bg-color">SpringBoot</span>
                    </a>
                    
                    <a href="/tags/Jenkins/">
                        <span class="chip bg-color">Jenkins</span>
                    </a>
                    
                    <a href="/tags/Gitee/">
                        <span class="chip bg-color">Gitee</span>
                    </a>
                    
                    <a href="/tags/%E8%BF%90%E7%BB%B4/">
                        <span class="chip bg-color">运维</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2024/08/06/continuousoptimization/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/50.jpg" class="responsive-img" alt="Continuous Optimization">
                        
                        <span class="card-title">Continuous Optimization</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2024-08-06
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/Mathematics/" class="post-category">
                                    Mathematics
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Mathematics/">
                        <span class="chip bg-color">Mathematics</span>
                    </a>
                    
                    <a href="/tags/AnalyticGeometry/">
                        <span class="chip bg-color">AnalyticGeometry</span>
                    </a>
                    
                    <a href="/tags/%E7%AC%94%E8%AE%B0/">
                        <span class="chip bg-color">笔记</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>


  <!-- 是否加载使用自带的 prismjs. -->
  <script type="text/javascript" src="/libs/prism/prism.min.js"></script>


<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>


<script src="https://cdn.bootcss.com/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
    MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$', '$'], ['\\(', '\\)']]}
    });
</script>



    <footer class="page-footer bg-color">
    

    <div class="container row center-align"
         style="margin-bottom: 0px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024</span>
            
            <a href="/about" target="_blank">Jay</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Eliauk-L" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:2571368706@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>







    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=2571368706" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 2571368706" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>







</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    

    
    
    

    <!-- 雪花特效 -->
     
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/libs/others/snow.js"><\/script>');
            }
        </script>
    

    <!-- 鼠标星星特效 -->
    

    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
